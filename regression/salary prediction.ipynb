{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data Assignment\n",
    "\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this note, I will build a variant of regression models to predict salary on test data. There are 1 million observations in train and test data, respectively. Each of them has 7 features (attributes): **X = companyId**, **jobType**, **degree**, **major**, **industry**, **yearsExperience** and **milesFromMetropolis**. The first five attributes are categorical, whereas the last two are numeric. The target variable **y = salary** is numeric too. Therefore, this is a supervised learning, regression problem. \n",
    "\n",
    "**NOTE:** Through the script, I will designate data from **train_features_2013-03-07.csv**+**test_salary_2013-03-07.csv** as `train_data`, and data from **test_features_2013-03-07.csv** as `task_data`. We only use `train_data` to train regression models, and use features from `task_data` to generate the salary table for this assignment's task.\n",
    "\n",
    "Before using the data to build predictive models, in addition to examine whether data is clean, we implemented `pandas` to preprocess data: (1) `Join train_feature + train_salary` to form `train_data`. For each observation, we need to macth **X** and **y** by **jobId**. (2) `Convert categorical variables to dummy variables`. Since there are categorical variables in the data (e.g. **jobType** = 'SENIOR', 'CTO', 'CFO' etc), we need to convert the catgeorical variables to the one-hot-encoding representation. Then the number of features becomes to 94. (3) `Concatenate train_data and task_data`. Before converting, we need to concatenate train and task dataFrame, in order to guarantee they have consistent feature columns. After concatenating, the number of observations in the table becomes 2 million and then we convert the entire data with OHE representation. (4) `Fetch the first million observation as train_data for models`. Since only the first million observations have target values **y**, we only use the first half data `train_data` to train models, and the second half, `task_data`, to generate `test_salaries.csv` for the assignment.\n",
    "\n",
    "Next I implemented `scikit-learn` library to build three regression models: (1) ridge regression $-$ a linear model with $L_2$ regularization, and two nonlinear models $-$ (2) decision tree and (3) random forest. To compare model performance, we split `train_data` into training (80%) and test (20%) datasets. Use the training set to train models and the test dataset to compare the models. In the linear model, I implement 10-fold cross-validation to search for optimal hyperparameter of the $L_2$ regularization. For the decision tree and random forest, I performed grid search to avoid overfitting. For model comparison, I used **two metics** $-$ **MSE**, mean-sqaure-errors and, $R^2$, the portion of data variance explained by the models. A lower **MSE** or higher (adjusted) $R^2$ implies better regression model performance.\n",
    "\n",
    "For most supervised machine learning problems, I used to start with linear models $-$ simple and have easy interpretation. Then take the linear models as baseline, and further examine if non-linear models significantly improve accuracy. All the models show lower **MSE** than that from baseline $-$ mean salary. This tells the ML models have better job to describe data variance.\n",
    "\n",
    "By comparing $R^2$ and **MSE**, we found that the most important feature to determine salary is **jobType** and then **yearExpereince**, **milesFromMetropolis** and **industry**....., since the model without **jobType** has the most significant drop on $R^2$ as well as increase on **MSE**, compared to the model using all features. In ridge regression, we can also list the coefficients to rank the feature importance and identify positive/negative contribution.\n",
    "\n",
    "The content is as follows:\n",
    "     0. Preprocess Data\n",
    "     1. Split training data to training/test datasets\n",
    "     2. Build Regression Models\n",
    "             2.0 Baseline\n",
    "             2.1 Ridge regression\n",
    "                * Feature importance interpretation for ridge regression\n",
    "             2.2 Decision Tree\n",
    "             2.3 Random Forest\n",
    "                * Feature importance interpretation for random forest\n",
    "             2.4 Model Comparison\n",
    "     3. Generate Salary Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import grid_search\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_csv(\"train_features_2013-03-07.csv\")\n",
    "train_salary = pd.read_csv(\"train_salaries_2013-03-07.csv\")\n",
    "task_features = pd.read_csv(\"test_features_2013-03-07.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_features` has dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobId</th>\n",
       "      <th>companyId</th>\n",
       "      <th>jobType</th>\n",
       "      <th>degree</th>\n",
       "      <th>major</th>\n",
       "      <th>industry</th>\n",
       "      <th>yearsExperience</th>\n",
       "      <th>milesFromMetropolis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JOB1362684407687</td>\n",
       "      <td>COMP37</td>\n",
       "      <td>CFO</td>\n",
       "      <td>MASTERS</td>\n",
       "      <td>MATH</td>\n",
       "      <td>HEALTH</td>\n",
       "      <td>10</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOB1362684407688</td>\n",
       "      <td>COMP19</td>\n",
       "      <td>CEO</td>\n",
       "      <td>HIGH_SCHOOL</td>\n",
       "      <td>NONE</td>\n",
       "      <td>WEB</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JOB1362684407689</td>\n",
       "      <td>COMP52</td>\n",
       "      <td>VICE_PRESIDENT</td>\n",
       "      <td>DOCTORAL</td>\n",
       "      <td>PHYSICS</td>\n",
       "      <td>HEALTH</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JOB1362684407690</td>\n",
       "      <td>COMP38</td>\n",
       "      <td>MANAGER</td>\n",
       "      <td>DOCTORAL</td>\n",
       "      <td>CHEMISTRY</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JOB1362684407691</td>\n",
       "      <td>COMP7</td>\n",
       "      <td>VICE_PRESIDENT</td>\n",
       "      <td>BACHELORS</td>\n",
       "      <td>PHYSICS</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              jobId companyId         jobType       degree      major  \\\n",
       "0  JOB1362684407687    COMP37             CFO      MASTERS       MATH   \n",
       "1  JOB1362684407688    COMP19             CEO  HIGH_SCHOOL       NONE   \n",
       "2  JOB1362684407689    COMP52  VICE_PRESIDENT     DOCTORAL    PHYSICS   \n",
       "3  JOB1362684407690    COMP38         MANAGER     DOCTORAL  CHEMISTRY   \n",
       "4  JOB1362684407691     COMP7  VICE_PRESIDENT    BACHELORS    PHYSICS   \n",
       "\n",
       "  industry  yearsExperience  milesFromMetropolis  \n",
       "0   HEALTH               10                   83  \n",
       "1      WEB                3                   73  \n",
       "2   HEALTH               10                   38  \n",
       "3     AUTO                8                   17  \n",
       "4  FINANCE                8                   16  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, `test_features` has dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 8)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobId</th>\n",
       "      <th>companyId</th>\n",
       "      <th>jobType</th>\n",
       "      <th>degree</th>\n",
       "      <th>major</th>\n",
       "      <th>industry</th>\n",
       "      <th>yearsExperience</th>\n",
       "      <th>milesFromMetropolis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JOB1362685407687</td>\n",
       "      <td>COMP33</td>\n",
       "      <td>MANAGER</td>\n",
       "      <td>HIGH_SCHOOL</td>\n",
       "      <td>NONE</td>\n",
       "      <td>HEALTH</td>\n",
       "      <td>22</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOB1362685407688</td>\n",
       "      <td>COMP13</td>\n",
       "      <td>JUNIOR</td>\n",
       "      <td>NONE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JOB1362685407689</td>\n",
       "      <td>COMP10</td>\n",
       "      <td>CTO</td>\n",
       "      <td>MASTERS</td>\n",
       "      <td>BIOLOGY</td>\n",
       "      <td>HEALTH</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JOB1362685407690</td>\n",
       "      <td>COMP21</td>\n",
       "      <td>MANAGER</td>\n",
       "      <td>HIGH_SCHOOL</td>\n",
       "      <td>NONE</td>\n",
       "      <td>OIL</td>\n",
       "      <td>14</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JOB1362685407691</td>\n",
       "      <td>COMP36</td>\n",
       "      <td>JUNIOR</td>\n",
       "      <td>DOCTORAL</td>\n",
       "      <td>BIOLOGY</td>\n",
       "      <td>OIL</td>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              jobId companyId  jobType       degree    major industry  \\\n",
       "0  JOB1362685407687    COMP33  MANAGER  HIGH_SCHOOL     NONE   HEALTH   \n",
       "1  JOB1362685407688    COMP13   JUNIOR         NONE     NONE     AUTO   \n",
       "2  JOB1362685407689    COMP10      CTO      MASTERS  BIOLOGY   HEALTH   \n",
       "3  JOB1362685407690    COMP21  MANAGER  HIGH_SCHOOL     NONE      OIL   \n",
       "4  JOB1362685407691    COMP36   JUNIOR     DOCTORAL  BIOLOGY      OIL   \n",
       "\n",
       "   yearsExperience  milesFromMetropolis  \n",
       "0               22                   73  \n",
       "1               20                   47  \n",
       "2               17                    9  \n",
       "3               14                   96  \n",
       "4               10                   44  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_salary` is a dataFrame to have **salary** and **jobId**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobId</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JOB1362684407687</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOB1362684407688</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JOB1362684407689</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JOB1362684407690</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JOB1362684407691</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              jobId  salary\n",
       "0  JOB1362684407687     130\n",
       "1  JOB1362684407688     101\n",
       "2  JOB1362684407689     137\n",
       "3  JOB1362684407690     142\n",
       "4  JOB1362684407691     163"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_salary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Examine if data is clean\n",
    "\n",
    "We go through all data points to see whether there exists `Nan` or missing data. The following results show the data is clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jobId                  0\n",
       "companyId              0\n",
       "jobType                0\n",
       "degree                 0\n",
       "major                  0\n",
       "industry               0\n",
       "yearsExperience        0\n",
       "milesFromMetropolis    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jobId     0\n",
       "salary    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_salary.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jobId                  0\n",
       "companyId              0\n",
       "jobType                0\n",
       "degree                 0\n",
       "major                  0\n",
       "industry               0\n",
       "yearsExperience        0\n",
       "milesFromMetropolis    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_features.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Join train_features and salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.merge(train_features, train_salary, on='jobId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4 Concatenate train and task data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_data, task_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have entire 2 million observations in the data pool. We can summarize the categorical variables as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of companyId: 63\n",
      "number of jobType: 8\n",
      "number of degree: 5\n",
      "number of major: 9\n",
      "number of indutry: 7\n"
     ]
    }
   ],
   "source": [
    "print ('number of companyId:', len(set(data['companyId'].tolist())))\n",
    "print ('number of jobType:', len(set(data['jobType'].tolist())))\n",
    "print ('number of degree:', len(set(data['degree'].tolist())))\n",
    "print ('number of major:', len(set(data['major'].tolist())))\n",
    "print ('number of indutry:', len(set(data['industry'].tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.5 Convert categorical variables to OHE repesentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['companyId','jobType', 'degree', 'major', 'industry',\n",
    "            'yearsExperience','milesFromMetropolis', 'salary']]\n",
    "data= pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are 95 columns (including **salary**), so the number of features is 94. It used dummy variable. For example, **jobType = CEO**, **jobType = CFO** converts to (**jobType_CEO = 1**, **jobType_CFO = 0**) and (**jobType_CEO = 0**, **jobType_CFO = 1**), respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000000, 95)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearsExperience</th>\n",
       "      <th>milesFromMetropolis</th>\n",
       "      <th>salary</th>\n",
       "      <th>companyId_COMP0</th>\n",
       "      <th>companyId_COMP1</th>\n",
       "      <th>companyId_COMP10</th>\n",
       "      <th>companyId_COMP11</th>\n",
       "      <th>companyId_COMP12</th>\n",
       "      <th>companyId_COMP13</th>\n",
       "      <th>companyId_COMP14</th>\n",
       "      <th>...</th>\n",
       "      <th>major_MATH</th>\n",
       "      <th>major_NONE</th>\n",
       "      <th>major_PHYSICS</th>\n",
       "      <th>industry_AUTO</th>\n",
       "      <th>industry_EDUCATION</th>\n",
       "      <th>industry_FINANCE</th>\n",
       "      <th>industry_HEALTH</th>\n",
       "      <th>industry_OIL</th>\n",
       "      <th>industry_SERVICE</th>\n",
       "      <th>industry_WEB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>83</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   yearsExperience  milesFromMetropolis  salary  companyId_COMP0  \\\n",
       "0               10                   83   130.0                0   \n",
       "1                3                   73   101.0                0   \n",
       "2               10                   38   137.0                0   \n",
       "3                8                   17   142.0                0   \n",
       "4                8                   16   163.0                0   \n",
       "\n",
       "   companyId_COMP1  companyId_COMP10  companyId_COMP11  companyId_COMP12  \\\n",
       "0                0                 0                 0                 0   \n",
       "1                0                 0                 0                 0   \n",
       "2                0                 0                 0                 0   \n",
       "3                0                 0                 0                 0   \n",
       "4                0                 0                 0                 0   \n",
       "\n",
       "   companyId_COMP13  companyId_COMP14      ...       major_MATH  major_NONE  \\\n",
       "0                 0                 0      ...                1           0   \n",
       "1                 0                 0      ...                0           1   \n",
       "2                 0                 0      ...                0           0   \n",
       "3                 0                 0      ...                0           0   \n",
       "4                 0                 0      ...                0           0   \n",
       "\n",
       "   major_PHYSICS  industry_AUTO  industry_EDUCATION  industry_FINANCE  \\\n",
       "0              0              0                   0                 0   \n",
       "1              0              0                   0                 0   \n",
       "2              1              0                   0                 0   \n",
       "3              0              1                   0                 0   \n",
       "4              1              0                   0                 1   \n",
       "\n",
       "   industry_HEALTH  industry_OIL  industry_SERVICE  industry_WEB  \n",
       "0                1             0                 0             0  \n",
       "1                0             0                 0             1  \n",
       "2                1             0                 0             0  \n",
       "3                0             0                 0             0  \n",
       "4                0             0                 0             0  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.6 Fetch the first million as train_data, and the second as task_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.iloc[:1000000,:]\n",
    "task_data = data.iloc[1000000:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we designate the first 1 million data for `train_data` to train ML models. The second million `task_data` is only used to generate the salary table. In `task_data` the **salary** column is useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 95), (1000000, 95))"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, task_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Split training data to training/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(train_data.columns)\n",
    "features.remove('salary')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data[features], train_data['salary'], test_size=0.2);\n",
    "X_train.shape, y_train.shape;\n",
    "y_train = y_train.tolist();\n",
    "y_test = y_test.tolist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Regression Models\n",
    "\n",
    "In this section, we built a baseline model: the mean salary and three regression models: (1) Ridge regression: linear regression model with $L_2$ regularization (2) Decision tree, and (3) Random Forest. All the ML models show lower **MSE** than the baseline; thus we can judge the ML models work. The best performance is given by random forest regressor, but it is time-consuming to train the model, and only slightly better than ridge regression. Therefore, if considering production and efficiency, I would suggest to implement the ridge regression as ML pipeline.\n",
    "\n",
    "\n",
    "## 2.0 Baseline\n",
    "\n",
    "Let's start with an easy baseline model. The predicted salary for each **jobId** is simply given by mean value of salaries in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of baseline: 1497.84\n"
     ]
    }
   ],
   "source": [
    "mean_salary = np.mean(y_test)\n",
    "print ('MSE of baseline:', round(np.mean([(y_test[i]-mean_salary)**2 for i in range(len(y_test))]),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as predictive models we build give lower **MSE** than 1497.84, we can judge our models work since it is able to describes data variance.\n",
    "\n",
    "## 2.1 Ridge Regressor\n",
    "\n",
    "Before implementing the ridge regression model, we should standardize the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = preprocessing.scale(X_train)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In training models, I used 10-fold cross-validation for grid search on optimal hyperparameter of $L_2$ regularization, and chosen the one giving highest $R^2$ on the cross validation dataset as the optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent for training: 734.8082828521729\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "best_ridge = None\n",
    "max_rscore = -1\n",
    "best_lambda = -1\n",
    "for lambda_i in range(20, 70, 2):\n",
    "    ridge = linear_model.Ridge(alpha=lambda_i)\n",
    "    cv_score = cross_val_score(ridge, X_train_scaled, y_train, cv=10)\n",
    "    if np.mean(cv_score) > max_rscore:\n",
    "        max_rscore = np.mean(cv_score)\n",
    "        best_ridge = ridge\n",
    "        best_lambda = lambda_i\n",
    "\n",
    "best_ridge.fit(X_train_scaled, y_train)\n",
    "print ('time spent for training:', time.time()-t0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal hyperparameter for regularization $\\lambda =50$. Then we input test dataset on the model to find out $R^2=0.742$, meaning the model almost explained 75% data variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model R square for RR: 0.742484944309\n"
     ]
    }
   ],
   "source": [
    "print ('model R square for RR:', best_ridge.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we check the **MSE** on training/test datasets. We can see the **MSE** shows much lower than that from baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for training set: 384.15 , MSE for test set: 385.67\n"
     ]
    }
   ],
   "source": [
    "train_pred = best_ridge_model.predict(X_train_scaled)\n",
    "test_pred = best_ridge_model.predict(X_test_scaled)\n",
    "print ('MSE for training set:', round(np.mean([(train_pred[i]-y_train[i])**2 for i in range(len(train_pred))]),2),\n",
    "      ', MSE for test set:', round(np.mean([(test_pred[i]-y_test[i])**2 for i in range(len(test_pred))]),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance interpretation for ridge regression\n",
    "\n",
    "Next we will interpret the feature importance. In the linear regression, with standardized data, we can directly compare the predictor coefficients as importance. We show the coefficient magnitudes in the descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yearsExperience</td>\n",
       "      <td>14.483164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jobType_CEO</td>\n",
       "      <td>9.160693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jobType_CFO</td>\n",
       "      <td>5.928725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jobType_CTO</td>\n",
       "      <td>5.906185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>industry_OIL</td>\n",
       "      <td>5.158926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature     weight\n",
       "0  yearsExperience  14.483164\n",
       "1      jobType_CEO   9.160693\n",
       "2      jobType_CFO   5.928725\n",
       "3      jobType_CTO   5.906185\n",
       "4     industry_OIL   5.158926"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = best_ridge.coef_\n",
    "v = sorted(range(len(weights)), key=lambda k: weights[k], reverse=True)\n",
    "sorted_features = [features[i] for i in v]\n",
    "sorted_weights = [weights[i] for i in v]\n",
    "df = pd.DataFrame({'feature': sorted_features, 'weight': sorted_weights})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>industry_EDUCATION</td>\n",
       "      <td>-5.773449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>jobType_JUNIOR</td>\n",
       "      <td>-7.303432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>jobType_JANITOR</td>\n",
       "      <td>-11.469931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>milesFromMetropolis</td>\n",
       "      <td>-11.536242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature     weight\n",
       "90   industry_EDUCATION  -5.773449\n",
       "91       jobType_JUNIOR  -7.303432\n",
       "92      jobType_JANITOR -11.469931\n",
       "93  milesFromMetropolis -11.536242"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "showing **yearExpereince** plays the most important positive role for a single feature in the regression model $-$ more **yearExpereince** contributes higher salaries. On the other hand, **milesFromMetropolis** has the most negative contribution to regression $-$ higher **milesFromMetropolis** corresponds to lower salaries. \n",
    "\n",
    "However, we have to notice that the majority of features came from OHE representation, like both **jobType_CEO** and **jobType_CFO** from **jobType**, so the importance of the features has been 'diluted'. To further explore the feature importance, we simply build a variant simple regression models which considers all features except the ones we are interested in. If (adjusted) $R^2$ reduces a lot or **MSE** increases a lot, it means the absent feature is important to explain model variance.\n",
    "\n",
    "For exmaple, the $R^2$, adjusted $R^2$ and **MSE** without **yearExpereince** are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_sq = 0.601 , adjusted R_sq= 0.601\n",
      "MSE: 597.49\n"
     ]
    }
   ],
   "source": [
    "features_2 = list(X_train.columns)\n",
    "features_2.remove('yearsExperience')\n",
    "reg = linear_model.LinearRegression().fit(X_train[features_2], y_train)\n",
    "R_sq = reg.score(X_test[features_2], y_test)\n",
    "print ('R_sq =', round(R_sq,3), ', adjusted R_sq=', round(1-(1-R_sq)*(1000000)/(1000000-93-1),3))\n",
    "pred = reg.predict(X_test[features_2])\n",
    "print ('MSE:', round(np.mean([(pred[i]-y_test[i])**2 for i in range(len(pred))]),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, without **milesFromMetropolis**, $R^2$, adjusted $R^2$ and **MSE** are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_sq = 0.654 , adjusted R_sq= 0.654\n",
      "MSE: 518.83\n"
     ]
    }
   ],
   "source": [
    "features_2 = list(X_train.columns)\n",
    "features_2.remove('milesFromMetropolis')\n",
    "reg = linear_model.LinearRegression().fit(X_train[features_2], y_train)\n",
    "R_sq = reg.score(X_test[features_2], y_test)\n",
    "print ('R_sq =', round(R_sq,3), ', adjusted R_sq=', round(1-(1-R_sq)*(1000000-1)/(1000000-93-1),3))\n",
    "pred = reg.predict(X_test[features_2])\n",
    "print ('MSE:', round(np.mean([(pred[i]-y_test[i])**2 for i in range(len(pred))]),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look up the importance of the categorical features: **jobType**, **industry**, **degree**, **major** and **companyId**. For convenience, we define the following function to build regression models without the above features, and compute $R^2$, adjusted $R^2$ and **MSE** for different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_R_sq(feature):\n",
    "    features_2 = list(X_train.columns)\n",
    "    types = [x for x in features_2 if x.split(\"_\")[0] == feature]\n",
    "    features_2 = [x for x in features_2 if x not in types]\n",
    "    reg = linear_model.LinearRegression().fit(X_train[features_2], y_train)\n",
    "    R_sq = reg.score(X_test[features_2], y_test)\n",
    "    #print (feature, 'R_sq =', round(R_sq,3), ', adjusted R_sq=', round(1-(1-R_sq)*(len(y_test)-1)/(len(y_test)-(94-len(types))-1),3))\n",
    "    pred = reg.predict(X_test[features_2])\n",
    "    print (feature, 'R_sq =', round(R_sq,3), ', adjusted R_sq=', round(1-(1-R_sq)*(len(y_test)-1)/(len(y_test)-(94-len(types))-1),3), \n",
    "           ', MSE:', round(np.mean([(pred[i]-y_test[i])**2 for i in range(len(pred))]),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R^2$, adjusted $R^2$ and **MSE** for **jobType**, **industry**, **degree**, **major** and **companyId** are respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobType R_sq = 0.486 , adjusted R_sq= 0.486 , MSE: 769.61\n",
      "industry R_sq = 0.655 , adjusted R_sq= 0.655 , MSE: 516.71\n",
      "degree R_sq = 0.73 , adjusted R_sq= 0.73 , MSE: 403.72\n",
      "major R_sq = 0.735 , adjusted R_sq= 0.735 , MSE: 397.48\n",
      "companyId R_sq = 0.743 , adjusted R_sq= 0.742 , MSE: 385.69\n"
     ]
    }
   ],
   "source": [
    "compute_R_sq(\"jobType\")\n",
    "compute_R_sq(\"industry\")\n",
    "compute_R_sq(\"degree\")\n",
    "compute_R_sq(\"major\")\n",
    "compute_R_sq(\"companyId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model without **jobType** shows the most significant drop on $R^2$ as well as most significant increase on MSE (compared to $R^2=0.7424$ and MSE = 385.67 using all features). Hence we can conclude that the most important feature to determine the salary is **jobType**, second are **yearExpereince**, and then **milesFromMetropolis**,  **industry**... The least feature is **companyId**. \n",
    "\n",
    "The following is the comparison of models without the features:\n",
    "\n",
    "| w/o feature | MSE increase | $R^2$ drop |\n",
    "|-------|-----| ------|  \n",
    "| **jobType**   |383.94|  0.256  |    \n",
    "| **yearsExperience**   |211.82|  0.141  |     \n",
    "| **milesFromMetropolis**   |133.16| 0.088  |     \n",
    "|**industry** | 131.04 | 0.087 |  \n",
    "| **degree**  | 18.05 | 0.012 |  \n",
    "| **major**    | 11.81  | 0.007 |  \n",
    "| **companyId** | 0.02  | ~ 0  | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Decision Tree Regressor\n",
    "\n",
    "For the decision tree regressor, we do grid search for maximum depth and minimum number of samples on leaf. Due to limited time, here I only use 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent for training: 954.8653700351715\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "decTreeReg = DecisionTreeRegressor(random_state=10)\n",
    "parameters = {'max_depth':[5,15,20,25,30],'min_samples_leaf':[5,10,20,30]}\n",
    "best_tree = grid_search.GridSearchCV(decTreeReg, parameters, cv=5, verbose=0, n_jobs=-1);\n",
    "best_tree.fit(X_train, y_train);\n",
    "print ('time spent for training:', time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=20, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "           min_samples_leaf=30, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
       "           splitter='best')"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the best decision tree is given by max_depth=20 and min_samples_leaf=30. Decision tree regressor gives similar $R^2$ but slightly lower **MSE** on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model R square for DT: 0.742831298822\n"
     ]
    }
   ],
   "source": [
    "print ('model R square for DT:', best_tree.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for training set: 347.643 , MSE for test set: 385.199\n"
     ]
    }
   ],
   "source": [
    "train_pred = best_tree.predict(X_train)\n",
    "test_pred = best_tree.predict(X_test)\n",
    "print ('MSE for training set:', round(np.mean([(train_pred[i]-y_train[i])**2 for i in range(len(train_pred))]),3),\n",
    "      ', MSE for test set:', round(np.mean([(test_pred[i]-y_test[i])**2 for i in range(len(test_pred))]),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Random Forest Regressor\n",
    "\n",
    "For the random forest regressor, it is easy to get overfitting results. Therefore, grid search is important. Due to limited time, here I do one-time training (wihtout cross-validation). In addition to maximum depth and minimum number of sample, we also grid search on number of predictors (estimators)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent for training: 11650.994484901428\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "rfReg = RandomForestRegressor()\n",
    "parameters = {'n_estimators': [25, 50, 75, 94], 'max_depth':[5,10,15], 'min_samples_leaf':[5,10]}\n",
    "best_rfReg = grid_search.GridSearchCV(rfReg, parameters, verbose=0, n_jobs=-1)\n",
    "best_rfReg.fit(X_train, y_train)\n",
    "print ('time spent for training:', time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=10,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=94, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfReg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode R square for RF: 0.743769542091\n"
     ]
    }
   ],
   "source": [
    "print ('mode R square for RF:', best_rfReg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for training set: 362.68 , MSE for test set: 383.79\n"
     ]
    }
   ],
   "source": [
    "train_pred = best_rfReg.predict(X_train)\n",
    "test_pred = best_rfReg.predict(X_test)\n",
    "print ('MSE for training set:', round(np.mean([(train_pred[i]-y_train[i])**2 for i in range(len(train_pred))]),2),\n",
    "      ', MSE for test set:', round(np.mean([(test_pred[i]-y_test[i])**2 for i in range(len(test_pred))]),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance interpretation for random forest\n",
    "\n",
    "We can use random forest to determine feature importance. The importance unforunately cannot tell positive or negative contribution. For example, the largest magnitude is **jobType_JANITOR**, which corresponds to second negative importance, and on the other hand, second rank **yearsExperience** has the most positive importance for a single feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.259482</td>\n",
       "      <td>jobType_JANITOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.188460</td>\n",
       "      <td>yearsExperience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.133651</td>\n",
       "      <td>milesFromMetropolis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.094746</td>\n",
       "      <td>jobType_JUNIOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.070744</td>\n",
       "      <td>major_NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   importance             variable\n",
       "0    0.259482      jobType_JANITOR\n",
       "1    0.188460      yearsExperience\n",
       "2    0.133651  milesFromMetropolis\n",
       "3    0.094746       jobType_JUNIOR\n",
       "4    0.070744           major_NONE"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = best_rfReg.best_estimator_.feature_importances_\n",
    "features = list(X_train.columns)\n",
    "\n",
    "v = sorted(range(len(importance)), key=lambda k: importance[k], reverse=True)\n",
    "sorted_importance = [importance[i] for i in v]\n",
    "sorted_features = [features[i] for i in v]\n",
    "\n",
    "df_importance = pd.DataFrame({'variable': sorted_features, 'importance' : sorted_importance})\n",
    "df_importance.sort_index().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Model Comparison\n",
    "\n",
    "Here we summarize the regression performance on the test dataset:\n",
    "\n",
    "| Model | MSE | $R^2$ | $T_{\\textrm{train}}$ (min) |\n",
    "|-------|-----| ------| ------------ |  \n",
    "| Ridge regression   |385.67|    0.742 |     12        |\n",
    "| Decision tree   |385.20|   0.743 |     16        |\n",
    "| Random forest   |383.79|  0.744 |     194      |\n",
    "\n",
    "Though the random forest regressor outperforms to the others, it is not necessary to be useful in production. The training time shows it is not efficient (more than 3 hours). The ridge regression model is good enough to capture the data variance and predict the salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Salary Profile\n",
    "\n",
    "With the optimal model, we are able to generate the salaries for each **jobId** using features from `task_data`. The following results show first 10 salaries using three regression models; we can see they roughly give similar salaries (at least within reasonable range). We still choose random forest regressor `best_rfReg` to generate `test_salaries.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 115.86049039,   92.26284307,  166.84533489,  105.7062408 ,\n",
       "        119.16529486,  158.40777886,   98.35967685,  118.84023827,\n",
       "        104.37623512,  108.15641365])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ridge.predict(scaler.transform(task_data[features]))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 124.19444444,   90.44186047,  181.2195122 ,  105.79069767,\n",
       "        111.38571429,  147.28      ,   96.48648649,  123.74358974,\n",
       "         96.83333333,  100.47368421])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree.predict(task_data[features])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 114.34513683,   92.30406848,  167.84192583,  107.91269304,\n",
       "        113.03449735,  151.27921345,   99.46773519,  123.75761675,\n",
       "        105.01468328,  100.81248462])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfReg.predict(task_data[features])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prediction = best_rfReg.predict(task_data[features])\n",
    "df = pd.DataFrame({\"jobId\": task_features['jobId'].tolist(), \"salary\": list(task_prediction)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobId</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JOB1362685407687</td>\n",
       "      <td>114.345137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOB1362685407688</td>\n",
       "      <td>92.304068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JOB1362685407689</td>\n",
       "      <td>167.841926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JOB1362685407690</td>\n",
       "      <td>107.912693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JOB1362685407691</td>\n",
       "      <td>113.034497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              jobId      salary\n",
       "0  JOB1362685407687  114.345137\n",
       "1  JOB1362685407688   92.304068\n",
       "2  JOB1362685407689  167.841926\n",
       "3  JOB1362685407690  107.912693\n",
       "4  JOB1362685407691  113.034497"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test_salaries.csv\", header=True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
